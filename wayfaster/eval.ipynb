{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick eval script I adapted from their code:\n",
    "\n",
    "Notes:\n",
    "I trained it for 13 epochs, turns out best model by evaluation is in 5th epoch, so thats the model we will use.\n",
    "\n",
    "How to use:\n",
    "\n",
    "1. Change `os.chdir(\"/home/richard/workspaces/VML/wayfaster\")`\n",
    "2. Change which datapoint to evaluate by `EVAL_BATCH_IDX = 0`. It's unshuffled (in order). I made batch_size = 1, so it's just a single datapoint (sequence of images, the sequence length is 6)\n",
    "\n",
    "Visualization outputs:\n",
    "- You could check generated imgs in wandb folder, or go to wandb online.\n",
    "\n",
    "  - Input visualization:\n",
    "    - eval_depth_target is the input depth image but downsampled.\n",
    "    - eval_pcloud is the input point cloud, transformed from the input depth image.\n",
    "  - Output visualizatrion: eval_mu, eval_nu is the linear,angular traction coefficient.\n",
    "\n",
    "  - The others are for Depth predictions (part of the architecture|)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/richard/workspaces/VML/wayfaster\n",
      "configs:\n",
      " {'TAG': 'temporal', 'TRAINING': {'EPOCHS': 20, 'BATCHSIZE': 4, 'WORKERS': 4, 'PRECISION': 16, 'DT': 0.1, 'HORIZON': 300, 'GAMMA': 1.0, 'DEPTH_WEIGHT': 0.1, 'VIS_INTERVAL': 500, 'VERBOSE': False}, 'MODEL': {'LOAD_NETWORK': 'checkpoints/checkpoint_epoch=5-valid_loss=0.2139.ckpt', 'DOWNSAMPLE': 8, 'LATENT_DIM': 64, 'TIME_LENGTH': 6, 'PREDICT_DEPTH': True, 'TRAIN_DEPTH': True, 'FUSE_PCLOUD': True, 'INPUT_SIZE': [320, 180], 'GRID_BOUNDS': {'xbound': [-2.0, 8.0, 0.1], 'ybound': [-5.0, 5.0, 0.1], 'zbound': [-1.0, 2.0, 0.2], 'dbound': [0.3, 8.0, 0.2]}}, 'OPTIMIZER': {'LR': 0.0001, 'WEIGHT_DECAY': 0.0001}, 'DATASET': {'TRAIN_DATA': ['dataset/zed2/data_train', 'dataset/realsense/data_train'], 'VALID_DATA': ['dataset/zed2/data_valid', 'dataset/realsense/data_valid'], 'CSV_FILE': 'rosbags.csv'}, 'AUGMENTATIONS': {'HORIZ_FLIP': 0.5, 'PCLOUD_DROPOUT': 0.3, 'MAX_TRANSLATION': 0.0, 'MAX_ROTATION': 0.0}, 'SEED': 42}\n",
      "Initializing dataset...\n",
      "Dataset initialized!\n",
      "Initializing dataset...\n",
      "Dataset initialized!\n",
      "Using Resnet34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/miniconda3/envs/wayfaster/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/richard/miniconda3/envs/wayfaster/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/richard/miniconda3/envs/wayfaster/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved network from checkpoints/checkpoint_epoch=5-valid_loss=0.2139.ckpt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# Custom packages\n",
    "from train.dataloader import Dataset\n",
    "from train.train_configs import get_cfg\n",
    "from train.trainer import TrainingModule\n",
    "from models.traversability_net import TravNet\n",
    "from train.utils import path_to_map\n",
    "\n",
    "# Change working directory to project level\n",
    "os.chdir(\"/home/richard/workspaces/VML/wayfaster\")\n",
    "print(os.getcwd())\n",
    "CONFIG_FILE_PATH = \"configs/temporal_model.yaml\"\n",
    "\n",
    "\n",
    "def parse_config():\n",
    "    # Load default configs and merge with args\n",
    "    config = get_cfg(CONFIG_FILE_PATH)\n",
    "    return config\n",
    "\n",
    "\n",
    "configs = parse_config()\n",
    "print(\"configs:\\n\", configs)\n",
    "pl.seed_everything(configs.SEED, workers=True)\n",
    "\n",
    "train_dataset = Dataset(configs, configs.DATASET.TRAIN_DATA)\n",
    "valid_dataset = Dataset(configs, configs.DATASET.VALID_DATA, weights=train_dataset.weights)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "# Initialize model and logger (it's pl.lightining module, model.model is the actual traversability network)\n",
    "model = TrainingModule(configs)\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"WayFASTER\",\n",
    "    log_model=\"all\",\n",
    ")\n",
    "\n",
    "# Load a previously trained network\n",
    "if configs.MODEL.LOAD_NETWORK is not None:\n",
    "    print(\"Loading saved network from {}\".format(configs.MODEL.LOAD_NETWORK))\n",
    "    pretrained_dict = torch.load(configs.MODEL.LOAD_NETWORK, map_location=\"cpu\")[\"state_dict\"]\n",
    "    model.load_state_dict(pretrained_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(\n",
    "    logger, model, image, pcloud, trav_map, pred_depth, depth_target, depth_mask, debug, executed_path, prefix=\"eval\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize the traversability network results.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): Tensor containing the images.\n",
    "        pcloud (torch.Tensor): Tensor containing the point clouds.\n",
    "        trav_map (torch.Tensor): Tensor containing the traversability map.\n",
    "        pred_depth (torch.Tensor): Tensor containing the predicted depth.\n",
    "        depth_target (torch.Tensor): Tensor containing the target depth.\n",
    "        depth_mask (torch.Tensor): Tensor containing the depth mask.\n",
    "        debug (torch.Tensor): Tensor containing the debug information.\n",
    "        executed_path (torch.Tensor): Tensor containing the executed path.\n",
    "        prefix (str): Prefix for the log keys.\n",
    "    \"\"\"\n",
    "    # Visualize the camera inputs\n",
    "    logger.log_image(key=prefix + \"_images\", images=[image.view(-1, *image.shape[2:])])\n",
    "\n",
    "    # Visualize the input point cloud\n",
    "    pcloud = torch.mean(pcloud, dim=2, keepdim=True)\n",
    "    pcloud = pcloud.view(-1, *pcloud.shape[2:])\n",
    "    logger.log_image(key=prefix + \"_pcloud\", images=[pcloud])\n",
    "\n",
    "    # Visualize the traversability map\n",
    "    logger.log_image(key=prefix + \"_mu\", images=[trav_map[:, :1]])\n",
    "\n",
    "    logger.log_image(key=prefix + \"_nu\", images=[trav_map[:, 1:]])\n",
    "\n",
    "    # Visualize the depth prediction\n",
    "    n_d = (model.grid_bounds[\"dbound\"][1] - model.grid_bounds[\"dbound\"][0]) / model.grid_bounds[\"dbound\"][2]\n",
    "    depth_pred = torch.argmax(pred_depth, dim=1, keepdim=True) / (n_d - 1)\n",
    "    logger.log_image(key=prefix + \"_depth_pred\", images=[depth_pred])\n",
    "\n",
    "    # Visualize the depth target\n",
    "    if model.predict_depth:\n",
    "        depth_target = depth_target.unsqueeze(1) / (n_d - 1)\n",
    "    else:\n",
    "        depth_target = depth_target.argmax(1).unsqueeze(1) / (n_d - 1)\n",
    "\n",
    "    logger.log_image(key=prefix + \"_depth_target\", images=[depth_target])\n",
    "\n",
    "    # Visualize the depth mask\n",
    "    logger.log_image(key=prefix + \"_depth_mask\", images=[depth_mask.unsqueeze(1)])\n",
    "\n",
    "    # Visualize the debug output\n",
    "    temp = torch.sum(debug, dim=1, keepdim=True)\n",
    "    temp = (temp - torch.min(temp)) / (torch.max(temp) - torch.min(temp))\n",
    "    logger.log_image(key=prefix + \"_debug\", images=[temp])\n",
    "\n",
    "    # Visualize the executed path\n",
    "    executed_path = executed_path / (torch.amax(executed_path, (1, 2, 3), keepdim=True) + model.eps)\n",
    "    logger.log_image(key=prefix + \"_path\", images=[executed_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found batch 0\n",
      "Forward Pass.\n",
      "Projecting path to map.\n",
      "Logging output to Wandb\n",
      "eval_loss  tensor(0.0481)\n",
      "eval_trav_loss  tensor(0.0187)\n",
      "eval_trav_error  tensor(0.0258)\n",
      "eval_depth_loss  tensor(0.2941)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate traversability network model\n",
    "trav_model: TravNet = model.model\n",
    "EVAL_BATCH_IDX = 0\n",
    "eval_batch = None\n",
    "\n",
    "for batch_idx, batch in enumerate(train_loader):\n",
    "    if batch_idx == EVAL_BATCH_IDX:\n",
    "        print(f\"Found batch {EVAL_BATCH_IDX}\")\n",
    "        eval_batch = batch\n",
    "        break\n",
    "\n",
    "with torch.no_grad():\n",
    "    trav_model.eval()\n",
    "\n",
    "    # Get data\n",
    "    color_img, pcloud, inv_intrinsics, extrinsics, path, target_trav, trav_weights, depth_target, depth_mask = eval_batch  # fmt: skip\n",
    "\n",
    "    # Forward pass\n",
    "    print(\"Forward Pass.\")\n",
    "    trav_map, pred_depth, debug = trav_model(color_img, pcloud, inv_intrinsics, extrinsics, depth_target)\n",
    "\n",
    "    # Project path to map\n",
    "    print(\"Projecting path to map.\")\n",
    "    executed_path = path_to_map(\n",
    "        path.unsqueeze(1),\n",
    "        torch.ones_like(path[..., 0, 0]).unsqueeze(1),\n",
    "        model.map_size,\n",
    "        model.map_resolution,\n",
    "        model.map_origin,\n",
    "    )\n",
    "\n",
    "    # Calculate traversability loss and error\n",
    "    trav_loss, trav_error = model.trav_criterion(path, trav_map, target_trav, trav_weights)\n",
    "\n",
    "    # Calculate depth classification loss\n",
    "    depth_target = depth_target.view(-1, *depth_target.shape[2:])\n",
    "    depth_mask = depth_mask.view(-1, *depth_mask.shape[2:])\n",
    "    depth_loss = model.depth_criterion(pred_depth, depth_target, depth_mask)\n",
    "\n",
    "    if model.train_depth:\n",
    "        loss = trav_loss + model.depth_weight * depth_loss\n",
    "    else:\n",
    "        loss = trav_loss\n",
    "\n",
    "    # Visualize results\n",
    "    print(\"Logging output to Wandb\")\n",
    "    visualize_results(\n",
    "        wandb_logger,\n",
    "        model,\n",
    "        color_img,\n",
    "        pcloud,\n",
    "        trav_map,\n",
    "        pred_depth,\n",
    "        depth_target,\n",
    "        depth_mask,\n",
    "        debug,\n",
    "        executed_path,\n",
    "        prefix=\"eval\",\n",
    "    )\n",
    "\n",
    "    # Print\n",
    "    print(\"eval_loss \", loss.item())\n",
    "    print(\"eval_trav_loss \", trav_loss.item())\n",
    "    print(\"eval_trav_error \", trav_error.item())\n",
    "    print(\"eval_depth_loss \", depth_loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wayfaster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
