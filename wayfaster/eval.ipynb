{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick eval script I adapted from their code:\n",
    "\n",
    "Notes:\n",
    "I trained it for 13 epochs, turns out best model by evaluation is in 5th epoch, so thats the model we will use.\n",
    "\n",
    "How to use:\n",
    "\n",
    "1. Change `os.chdir(\"/home/richard/workspaces/VML/wayfaster\")`\n",
    "2. Change which datapoint to evaluate by `EVAL_BATCH_IDX = 0`. It's unshuffled (in order). I made batch_size = 1, so it's just a single datapoint (sequence of images, the sequence length is 6)\n",
    "\n",
    "Visualization outputs:\n",
    "\n",
    "- You could check generated imgs in wandb folder, or go to wandb online.\n",
    "\n",
    "  - Input visualization:\n",
    "    - eval_depth_target is the input depth image but downsampled.\n",
    "    - eval_pcloud is the input point cloud, transformed from the input depth image.\n",
    "  - Output visualizatrion: eval_mu, eval_nu is the linear,angular traction coefficient.\n",
    "\n",
    "  - The others are for Depth predictions (part of the architecture|)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "# Custom packages\n",
    "from train.dataloader import Dataset\n",
    "from train.train_configs import get_cfg\n",
    "from train.trainer import TrainingModule\n",
    "from models.traversability_net import TravNet\n",
    "from train.utils import path_to_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory to project level\n",
    "os.chdir(\"/home/richard/workspaces/VML/wayfaster\")\n",
    "print(os.getcwd())\n",
    "CONFIG_FILE_PATH = \"configs/temporal_model.yaml\"\n",
    "\n",
    "\n",
    "def parse_config():\n",
    "    # Load default configs and merge with args\n",
    "    config = get_cfg(CONFIG_FILE_PATH)\n",
    "    return config\n",
    "\n",
    "\n",
    "configs = parse_config()\n",
    "print(\"configs:\\n\", configs)\n",
    "pl.seed_everything(configs.SEED, workers=True)\n",
    "\n",
    "train_dataset = Dataset(configs, configs.DATASET.TRAIN_DATA)\n",
    "# valid_dataset = Dataset(configs, configs.DATASET.VALID_DATA, weights=train_dataset.weights)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "# valid_loader = DataLoader(\n",
    "#     valid_dataset,\n",
    "#     batch_size=1,\n",
    "#     shuffle=False,\n",
    "#     drop_last=True,\n",
    "#     pin_memory=True,\n",
    "# )\n",
    "\n",
    "# Initialize model and logger (it's pl.lightining module, model.model is the actual traversability network)\n",
    "model = TrainingModule(configs)\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"WayFASTER\",\n",
    "    log_model=\"all\",\n",
    ")\n",
    "\n",
    "# Load a previously trained network\n",
    "if configs.MODEL.LOAD_NETWORK is not None:\n",
    "    print(\"Loading saved network from {}\".format(configs.MODEL.LOAD_NETWORK))\n",
    "    pretrained_dict = torch.load(configs.MODEL.LOAD_NETWORK, map_location=\"cpu\")[\"state_dict\"]\n",
    "    model.load_state_dict(pretrained_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(\n",
    "    logger, model, image, pcloud, trav_map, pred_depth, depth_target, depth_mask, debug, executed_path, prefix=\"eval\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize the traversability network results.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): Tensor containing the images.\n",
    "        pcloud (torch.Tensor): Tensor containing the point clouds.\n",
    "        trav_map (torch.Tensor): Tensor containing the traversability map.\n",
    "        pred_depth (torch.Tensor): Tensor containing the predicted depth.\n",
    "        depth_target (torch.Tensor): Tensor containing the target depth.\n",
    "        depth_mask (torch.Tensor): Tensor containing the depth mask.\n",
    "        debug (torch.Tensor): Tensor containing the debug information.\n",
    "        executed_path (torch.Tensor): Tensor containing the executed path.\n",
    "        prefix (str): Prefix for the log keys.\n",
    "    \"\"\"\n",
    "    # Visualize the camera inputs\n",
    "    logger.log_image(key=prefix + \"_images\", images=[image.view(-1, *image.shape[2:])])\n",
    "\n",
    "    # Visualize the input point cloud\n",
    "    pcloud = torch.mean(pcloud, dim=2, keepdim=True)\n",
    "    pcloud = pcloud.view(-1, *pcloud.shape[2:])\n",
    "    logger.log_image(key=prefix + \"_pcloud\", images=[pcloud])\n",
    "\n",
    "    # Visualize the traversability map\n",
    "    logger.log_image(key=prefix + \"_mu\", images=[trav_map[:, :1]])\n",
    "\n",
    "    logger.log_image(key=prefix + \"_nu\", images=[trav_map[:, 1:]])\n",
    "\n",
    "    # Visualize the depth prediction\n",
    "    n_d = (model.grid_bounds[\"dbound\"][1] - model.grid_bounds[\"dbound\"][0]) / model.grid_bounds[\"dbound\"][2]\n",
    "    depth_pred = torch.argmax(pred_depth, dim=1, keepdim=True) / (n_d - 1)\n",
    "    logger.log_image(key=prefix + \"_depth_pred\", images=[depth_pred])\n",
    "\n",
    "    # Visualize the depth target\n",
    "    if model.predict_depth:\n",
    "        depth_target = depth_target.unsqueeze(1) / (n_d - 1)\n",
    "    else:\n",
    "        depth_target = depth_target.argmax(1).unsqueeze(1) / (n_d - 1)\n",
    "\n",
    "    logger.log_image(key=prefix + \"_depth_target\", images=[depth_target])\n",
    "\n",
    "    # Visualize the depth mask\n",
    "    logger.log_image(key=prefix + \"_depth_mask\", images=[depth_mask.unsqueeze(1)])\n",
    "\n",
    "    # Visualize the debug output\n",
    "    temp = torch.sum(debug, dim=1, keepdim=True)\n",
    "    temp = (temp - torch.min(temp)) / (torch.max(temp) - torch.min(temp))\n",
    "    logger.log_image(key=prefix + \"_debug\", images=[temp])\n",
    "\n",
    "    # Visualize the executed path\n",
    "    executed_path = executed_path / (torch.amax(executed_path, (1, 2, 3), keepdim=True) + model.eps)\n",
    "    logger.log_image(key=prefix + \"_path\", images=[executed_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate traversability network model\n",
    "trav_model: TravNet = model.model\n",
    "EVAL_BATCH_IDX = 0\n",
    "\n",
    "eval_batch = list(train_dataset[EVAL_BATCH_IDX])\n",
    "for i in range(len(eval_batch)):\n",
    "    eval_batch[i] = eval_batch[i].unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    trav_model.eval()\n",
    "\n",
    "    # Get data\n",
    "    color_img, pcloud, inv_intrinsics, extrinsics, path, target_trav, trav_weights, depth_target, depth_mask = eval_batch  # fmt: skip\n",
    "    print(f\"{color_img.shape=}, {color_img.dtype=}\")\n",
    "    print(f\"{pcloud.shape=}, {pcloud.dtype=}\")\n",
    "\n",
    "    # Forward pass\n",
    "    print(\"Forward Pass.\")\n",
    "    trav_map, pred_depth, debug = trav_model(color_img, pcloud, inv_intrinsics, extrinsics, depth_target)\n",
    "\n",
    "    # Project path to map\n",
    "    print(\"Projecting path to map.\")\n",
    "    executed_path = path_to_map(\n",
    "        path.unsqueeze(1),\n",
    "        torch.ones_like(path[..., 0, 0]).unsqueeze(1),\n",
    "        model.map_size,\n",
    "        model.map_resolution,\n",
    "        model.map_origin,\n",
    "    )\n",
    "\n",
    "    # Calculate traversability loss and error\n",
    "    trav_loss, trav_error = model.trav_criterion(path, trav_map, target_trav, trav_weights)\n",
    "\n",
    "    # Calculate depth classification loss\n",
    "    depth_target = depth_target.view(-1, *depth_target.shape[2:])\n",
    "    depth_mask = depth_mask.view(-1, *depth_mask.shape[2:])\n",
    "    depth_loss = model.depth_criterion(pred_depth, depth_target, depth_mask)\n",
    "\n",
    "    if model.train_depth:\n",
    "        loss = trav_loss + model.depth_weight * depth_loss\n",
    "    else:\n",
    "        loss = trav_loss\n",
    "\n",
    "    # Visualize results\n",
    "    print(\"Logging output to Wandb\")\n",
    "    visualize_results(\n",
    "        wandb_logger,\n",
    "        model,\n",
    "        color_img,\n",
    "        pcloud,\n",
    "        trav_map,\n",
    "        pred_depth,\n",
    "        depth_target,\n",
    "        depth_mask,\n",
    "        debug,\n",
    "        executed_path,\n",
    "        prefix=\"eval\",\n",
    "    )\n",
    "\n",
    "    # Print\n",
    "    print(\"eval_loss \", loss.item())\n",
    "    print(\"eval_trav_loss \", trav_loss.item())\n",
    "    print(\"eval_trav_error \", trav_error.item())\n",
    "    print(\"eval_depth_loss \", depth_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying shadow attack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display the tensor\n",
    "def display_tensor_images(tensor):\n",
    "    \"\"\"\n",
    "    Display a tensor of shape (batch_size, sequence_length, 3, height, width)\n",
    "    as a grid of images with rows as batch indices and columns as sequence indices.\n",
    "    \"\"\"\n",
    "    batch_size, seq_length, channels, height, width = tensor.shape\n",
    "\n",
    "    # Create a figure with batch_size rows and seq_length columns\n",
    "    fig, axes = plt.subplots(batch_size, seq_length, figsize=(seq_length * 3, batch_size * 3))\n",
    "    fig.suptitle(\"Tensor Visualization: Rows=Batch, Columns=Sequence\", fontsize=16)\n",
    "\n",
    "    # Ensure axes is 2D even for batch_size=1 or seq_length=1\n",
    "    axes = np.array(axes).reshape(batch_size, seq_length)\n",
    "\n",
    "    for i in range(batch_size):  # Loop over batch\n",
    "        for j in range(seq_length):  # Loop over sequence\n",
    "            # Extract the image for batch `i` and sequence `j`\n",
    "            img = tensor[i, j].cpu().permute(1, 2, 0).numpy()  # Convert to (H, W, C) for visualization\n",
    "\n",
    "            # Normalize image to [0, 1] if necessary\n",
    "            img = (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "            # Display the image\n",
    "            axes[i, j].imshow(img)\n",
    "            axes[i, j].axis(\"off\")  # Hide axes\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)  # Adjust for suptitle\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wayfaster.adversarial_attacks.shadow_attacker_optimized import ShadowAttack\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# Evaluate traversability network model\n",
    "trav_model: TravNet = model.model\n",
    "trav_model = trav_model.to(device)\n",
    "pl.seed_everything(configs.SEED, workers=True)\n",
    "\n",
    "EVAL_BATCH_IDX = 356  # 1, 230, 1800,2700, 356\n",
    "\n",
    "eval_batch = list(train_dataset[EVAL_BATCH_IDX])\n",
    "for i in range(len(eval_batch)):\n",
    "    eval_batch[i] = eval_batch[i].unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    trav_model.eval()\n",
    "\n",
    "    # Get data\n",
    "    color_img, pcloud, inv_intrinsics, extrinsics, path, target_trav, trav_weights, depth_target, depth_mask = eval_batch  # fmt: skip\n",
    "    print(f\"{color_img.shape=}, {color_img.dtype=}\")\n",
    "    print(f\"{pcloud.shape=}, {pcloud.dtype=}\")\n",
    "    print(f\"{path.shape=}\")\n",
    "    print(f\"{target_trav.shape=}\")\n",
    "    print(f\"{depth_target.shape=}\")\n",
    "\n",
    "    # Forward pass on unperturbed input\n",
    "    print(\"Forward Pass on unperturbed input.\")\n",
    "    trav_map, pred_depth, debug = trav_model(color_img, pcloud, inv_intrinsics, extrinsics)\n",
    "\n",
    "    # Visualize unperturbed input and output\n",
    "    wandb_logger.log_image(\"unperturbed_images\", images=[color_img.view(-1, *color_img.shape[2:])])\n",
    "    wandb_logger.log_image(\"unperturbed_mu\", images=[trav_map[:, :1]])\n",
    "    wandb_logger.log_image(\"unperturbed_nu\", images=[trav_map[:, 1:]])\n",
    "\n",
    "    # unperturbed depth prediction\n",
    "    n_d = (model.grid_bounds[\"dbound\"][1] - model.grid_bounds[\"dbound\"][0]) / model.grid_bounds[\"dbound\"][2]\n",
    "    depth_pred = torch.argmax(pred_depth, dim=1, keepdim=True) / (n_d - 1)\n",
    "    wandb_logger.log_image(\"unperturbed_depth_pred\", images=[depth_pred])\n",
    "\n",
    "    # Perturb input data with shadow attack\n",
    "    img_h, img_w = color_img.shape[-2:]\n",
    "    attacker = ShadowAttack(trav_model)\n",
    "    attacker.PSO_params[\"num_iters\"] = 10\n",
    "    max_l1_loss, Xp = attacker.generate_attack(model_inputs=[color_img, pcloud, inv_intrinsics, extrinsics])\n",
    "    display_tensor_images(Xp)\n",
    "\n",
    "    # Forward pass on perturbed input\n",
    "    print(\"Forward Pass on perturbed input.\")\n",
    "    trav_map, pred_depth, debug = trav_model(Xp, pcloud, inv_intrinsics, extrinsics)\n",
    "\n",
    "    # Visualize perturbed input and output\n",
    "    wandb_logger.log_image(\"perturbed_images\", images=[Xp.view(-1, *Xp.shape[2:])])\n",
    "    wandb_logger.log_image(\"perturbed_mu\", images=[trav_map[:, :1]])\n",
    "    wandb_logger.log_image(\"perturbed_nu\", images=[trav_map[:, 1:]])\n",
    "    depth_pred = torch.argmax(pred_depth, dim=1, keepdim=True) / (n_d - 1)\n",
    "    wandb_logger.log_image(\"perturbed_depth_pred\", images=[depth_pred])\n",
    "\n",
    "    # Print\n",
    "    print(\"adv_loss \", max_l1_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVAL_BATCH_IDX = 22 # 356, 230, 120, 839,1200, 1,59, 22\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wayfaster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
